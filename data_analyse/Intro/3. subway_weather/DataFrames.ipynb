{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculating Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8\n",
      "-1.0\n",
      "0.0359210604054\n"
     ]
    }
   ],
   "source": [
    "a = pd.Series([1, 2, 3, 4])\n",
    "b = pd.Series([10, 20, 30, 40])\n",
    "c = pd.Series([10, 30, 20, 40])\n",
    "d = pd.Series([40, 30, 20, 10])\n",
    "e = pd.Series([20, 90, 10, 50])\n",
    "def standardize_data(values):\n",
    "    mean = values.mean()\n",
    "    std = values.std(ddof = 0)\n",
    "    return (values - mean)/std\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    standard_x = standardize_data(x)\n",
    "    standard_y = standardize_data(y) \n",
    "    return (standard_x*standard_y).mean()\n",
    "\n",
    "print(correlation(a, b))\n",
    "print(correlation(a, c))\n",
    "print(correlation(a, d))\n",
    "print(correlation(a, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>214.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn  EXITSn\n",
       "0       NaN     NaN\n",
       "1      23.0     8.0\n",
       "2      18.0    18.0\n",
       "3      71.0    54.0\n",
       "4     170.0    44.0\n",
       "5     214.0    42.0\n",
       "6      87.0    11.0\n",
       "7      10.0     3.0\n",
       "8      36.0    89.0\n",
       "9     153.0   333.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of vectorized operations on DataFrames:\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print (df1 + df2)\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print (df1 + df2)\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print (df1 + df2)\n",
    "\n",
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DataFrame applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     D\n",
      "Chris       C     F\n",
      "Dan         C     F\n",
      "Emilio      B     D\n",
      "Fred        C     F\n",
      "Greta       A     C\n",
      "Humbert     D     F\n",
      "Ivan        A     C\n",
      "James       B     D\n"
     ]
    }
   ],
   "source": [
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print (df.applymap(add_one))\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "def convert_grade(grade):\n",
    "    if grade >= 90 and grade <=100:\n",
    "        return 'A'\n",
    "    elif grade >= 80:\n",
    "        return 'B'\n",
    "    elif grade >= 70:\n",
    "        return 'C'\n",
    "    elif grade >= 60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return grades.applymap(convert_grade)\n",
    "print(convert_grades(grades_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DataFrame apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam1, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam2, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "        exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     B\n",
      "Chris       C     C\n",
      "Dan         C     C\n",
      "Emilio      B     B\n",
      "Fred        C     C\n",
      "Greta       A     A\n",
      "Humbert     D     D\n",
      "Ivan        A     A\n",
      "James       B     B\n",
      "            exam1     exam2\n",
      "Andre   -2.315341 -2.304599\n",
      "Barry    0.220191  0.386400\n",
      "Chris    0.020017 -0.096600\n",
      "Dan     -0.180156 -0.096600\n",
      "Emilio   0.753987  0.662400\n",
      "Fred    -0.513779 -0.441600\n",
      "Greta    0.887436  1.490400\n",
      "Humbert -0.847401 -0.786600\n",
      "Ivan     1.354508  1.007400\n",
      "James    0.620538  0.179400\n"
     ]
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if True:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print (convert_grades_curve(grades_df['exam1']))\n",
    "    print (convert_grades_curve(grades_df['exam2']))\n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print (grades_df.apply(convert_grades_curve))\n",
    "    \n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    df_mean = df.mean()\n",
    "    df_std = df.std(ddof = 0)\n",
    "    \n",
    "    return (df - df_mean)/df_std\n",
    "print(standardize(grades_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. DataFrame apply() Use Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     4\n",
      "b    40\n",
      "c    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if False:   \n",
    "    print (df.apply(np.mean))\n",
    "    print (df.apply(np.max))\n",
    "\n",
    "def sec_large(series):\n",
    "    sorted = series.sort_values()\n",
    "    return sorted.values[-2]\n",
    "\n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return df.apply(sec_large)\n",
    "print(second_largest(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Adding a DataFrame to a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    a   b   c   d   0   1   2   3\n",
      "0 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "1 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "2 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "3 NaN NaN NaN NaN NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Standardizing Each Column Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exam1     exam2\n",
      "Andre   -2.315341 -2.304599\n",
      "Barry    0.220191  0.386400\n",
      "Chris    0.020017 -0.096600\n",
      "Dan     -0.180156 -0.096600\n",
      "Emilio   0.753987  0.662400\n",
      "Fred    -0.513779 -0.441600\n",
      "Greta    0.887436  1.490400\n",
      "Humbert -0.847401 -0.786600\n",
      "Ivan     1.354508  1.007400\n",
      "James    0.620538  0.179400\n",
      "\n",
      "         exam1  exam2\n",
      "Andre      1.0   -1.0\n",
      "Barry      1.0   -1.0\n",
      "Chris      1.0   -1.0\n",
      "Dan        1.0   -1.0\n",
      "Emilio     1.0   -1.0\n",
      "Fred       1.0   -1.0\n",
      "Greta      1.0   -1.0\n",
      "Humbert    1.0   -1.0\n",
      "Ivan       1.0   -1.0\n",
      "James      1.0   -1.0\n"
     ]
    }
   ],
   "source": [
    "# Adding using +\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df + s)\n",
    "    \n",
    "# Adding with axis='index'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df.add(s, axis='index'))\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "# Adding with axis='columns'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print (df)\n",
    "    print ('') # Create a blank line between outputs\n",
    "    print (df.add(s, axis='columns'))\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    df_mean = df.mean()\n",
    "    df_std = df.std(ddof = 0)\n",
    "    return (df - df_mean)/df_std\n",
    "print(standardize(grades_df))\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    df_mean = df.mean(axis = 'columns')\n",
    "    df_std = df.std(ddof = 0, axis = 'columns')\n",
    "    subst = df.sub(df_mean, axis = 'index')\n",
    "    return subst.div(df_std, axis = 'index')\n",
    "print(\"\")\n",
    "print(standardize_rows(grades_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain\n",
      "0    1845.539439\n",
      "1    2028.196035\n",
      "Name: ENTRIESn_hourly, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb9dd68470>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEGCAYAAACD7ClEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEf9JREFUeJzt3X+MZWV9x/H3R1DaaqlYBoq7SxftYgtGV50iidHS0PKrjWATLfwhSE1XDSQ1tYlgm4BaEtuKRlLFrLIFEgVp0bKxWFxJldi6woArsCKyIMqwm2UUgloMCnz7xz1Trrt3fuzcu3Nxn/crubnnfs9zznnuZiefOc85Z55UFZKkNj1r3B2QJI2PISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlq2P7j7sBCDj744Fq9evW4uyFJvzRuvfXWH1TVxGLaPuNDYPXq1UxNTY27G5L0SyPJ9xbb1uEgSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMWfFgsySrgSuC3gKeA9VX1kSQvAD4DrAbuB95UVY8kCfAR4BTgMeAtVXVbt6+zgL/rdv33VXXFaL+OpN1c+Bvj7sG+5cJHx92DkVrMmcATwLuq6veAY4FzkhwFnAfcWFVrgBu7zwAnA2u61zrgUoAuNC4AXg0cA1yQ5KARfhdJ0h5aMASqasfsb/JV9WPgLmAFcCow+5v8FcBp3fKpwJXVsxl4fpLDgBOBTVX1cFU9AmwCThrpt5Ek7ZE9uiaQZDXwCuDrwKFVtQN6QQEc0jVbATzQt9l0V5urPug465JMJZmamZnZky5KkvbAokMgyfOAa4F3VtWP5ms6oFbz1HcvVq2vqsmqmpyYWNQfwpMkLcGiQiDJs+kFwKeq6rNdeWc3zEP3/lBXnwZW9W2+Etg+T12SNCYLhkB3t89lwF1V9aG+VRuBs7rls4Dr+upnpudY4NFuuOgG4IQkB3UXhE/oapKkMVnMfAKvAd4M3JFkS1d7D/AB4JokbwW+D7yxW3c9vdtDt9G7RfRsgKp6OMn7gVu6du+rqodH8i0kSUuyYAhU1VcZPJ4PcPyA9gWcM8e+NgAb9qSDkqS9xyeGJalhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDVsMX87SAtYfd5/jLsL+5T7P/An4+6C1AzPBCSpYYaAJDXMEJCkhhkCktQwQ0CSGraY6SU3JHkoyZ19tc8k2dK97p+dcSzJ6iQ/7Vv38b5tXpXkjiTbklzSTVspSRqjxdwiejnwz8CVs4Wq+vPZ5SQXA4/2tb+3qtYO2M+lwDpgM70pKE8CvrDnXZYkjcqCZwJVdRMwcC7g7rf5NwFXzbePJIcBB1bV17rpJ68ETtvz7kqSRmnYawKvBXZW1T19tSOSfCPJV5K8tqutAKb72kx3NUnSGA37xPAZ/OJZwA7g8Kr6YZJXAf+e5GgGT1Rfc+00yTp6Q0ccfvjhQ3ZRkjSXJZ8JJNkf+DPgM7O1qnq8qn7YLd8K3AscSe83/5V9m68Ets+176paX1WTVTU5MTGx1C5KkhYwzHDQHwHfrqr/H+ZJMpFkv275RcAa4L6q2gH8OMmx3XWEM4Hrhji2JGkEFnOL6FXA14CXJJlO8tZu1ensfkH4dcDtSb4J/Bvw9qqavaj8DuCTwDZ6ZwjeGSRJY7bgNYGqOmOO+lsG1K4Frp2j/RTw0j3snyRpL/KJYUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWrYYqaX3JDkoSR39tUuTPJgki3d65S+decn2Zbk7iQn9tVP6mrbkpw3+q8iSdpTizkTuBw4aUD9w1W1tntdD5DkKHpzDx/dbfOxJPt1k89/FDgZOAo4o2srSRqjxcwxfFOS1Yvc36nA1VX1OPDdJNuAY7p126rqPoAkV3dtv7XHPZYkjcww1wTOTXJ7N1x0UFdbATzQ12a6q81VHyjJuiRTSaZmZmaG6KIkaT5LDYFLgRcDa4EdwMVdPQPa1jz1gapqfVVNVtXkxMTEErsoSVrIgsNBg1TVztnlJJ8APt99nAZW9TVdCWzvlueqS5LGZElnAkkO6/v4BmD2zqGNwOlJDkhyBLAGuBm4BViT5Igkz6F38Xjj0rstSRqFBc8EklwFHAccnGQauAA4LslaekM69wNvA6iqrUmuoXfB9wngnKp6stvPucANwH7AhqraOvJvI0naI4u5O+iMAeXL5ml/EXDRgPr1wPV71DtJ0l7lE8OS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUsAVDIMmGJA8lubOv9k9Jvp3k9iSfS/L8rr46yU+TbOleH+/b5lVJ7kiyLcklSbJ3vpIkabEWcyZwOXDSLrVNwEur6mXAd4Dz+9bdW1Vru9fb++qXAuvoTT6/ZsA+JUnLbMEQqKqbgId3qX2xqp7oPm4GVs63jySHAQdW1deqqoArgdOW1mVJ0qiM4prAXwBf6Pt8RJJvJPlKktd2tRXAdF+b6a42UJJ1SaaSTM3MzIygi5KkQYYKgSR/CzwBfKor7QAOr6pXAH8NfDrJgcCg8f+aa79Vtb6qJqtqcmJiYpguSpLmsf9SN0xyFvCnwPHdEA9V9TjweLd8a5J7gSPp/ebfP2S0Eti+1GNLkkZjSWcCSU4C3g28vqoe66tPJNmvW34RvQvA91XVDuDHSY7t7go6E7hu6N5Lkoay4JlAkquA44CDk0wDF9C7G+gAYFN3p+fm7k6g1wHvS/IE8CTw9qqavaj8Dnp3Gv0qvWsI/dcRJEljsGAIVNUZA8qXzdH2WuDaOdZNAS/do95JkvYqnxiWpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDVsUSGQZEOSh5Lc2Vd7QZJNSe7p3g/q6klySZJtSW5P8sq+bc7q2t/TzVEsSRqjxZ4JXA6ctEvtPODGqloD3Nh9BjiZ3tzCa4B1wKXQCw16U1O+GjgGuGA2OCRJ47GoEKiqm4CHdymfClzRLV8BnNZXv7J6NgPPT3IYcCKwqaoerqpHgE3sHiySpGU0zDWBQ6tqB0D3fkhXXwE80NduuqvNVd9NknVJppJMzczMDNFFSdJ89saF4Qyo1Tz13YtV66tqsqomJyYmRto5SdLThgmBnd0wD937Q119GljV124lsH2euiRpTIYJgY3A7B0+ZwHX9dXP7O4SOhZ4tBsuugE4IclB3QXhE7qaJGlM9l9MoyRXAccBByeZpneXzweAa5K8Ffg+8Mau+fXAKcA24DHgbICqejjJ+4Fbunbvq6pdLzZLkpbRokKgqs6YY9XxA9oWcM4c+9kAbFh07yRJe5VPDEtSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDlhwCSV6SZEvf60dJ3pnkwiQP9tVP6dvm/CTbktyd5MTRfAVJ0lItanrJQarqbmAtQJL9gAeBz9GbU/jDVfXB/vZJjgJOB44GXgh8KcmRVfXkUvsgSRrOqIaDjgfurarvzdPmVODqqnq8qr5LbyL6Y0Z0fEnSEowqBE4Hrur7fG6S25NsSHJQV1sBPNDXZrqr7SbJuiRTSaZmZmZG1EVJ0q6GDoEkzwFeD/xrV7oUeDG9oaIdwMWzTQdsXoP2WVXrq2qyqiYnJiaG7aIkaQ6jOBM4GbitqnYCVNXOqnqyqp4CPsHTQz7TwKq+7VYC20dwfEnSEo0iBM6gbygoyWF9694A3NktbwROT3JAkiOANcDNIzi+JGmJlnx3EECSXwP+GHhbX/kfk6ylN9Rz/+y6qtqa5BrgW8ATwDneGSRJ4zVUCFTVY8Bv7lJ78zztLwIuGuaYkqTR8YlhSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDRjHR/P1J7kiyJclUV3tBkk1J7uneD+rqSXJJkm1Jbk/yymGPL0laulGdCfxhVa2tqsnu83nAjVW1Brix+wy9SenXdK91wKUjOr4kaQn21nDQqcAV3fIVwGl99SurZzPw/F0mppckLaNRhEABX0xya5J1Xe3QqtoB0L0f0tVXAA/0bTvd1X5BknVJppJMzczMjKCLkqRBhppovvOaqtqe5BBgU5Jvz9M2A2q1W6FqPbAeYHJycrf1kqTRGPpMoKq2d+8PAZ8DjgF2zg7zdO8Pdc2ngVV9m68Etg/bB0nS0gwVAkmem+TXZ5eBE4A7gY3AWV2zs4DruuWNwJndXULHAo/ODhtJkpbfsMNBhwKfSzK7r09X1X8muQW4Jslbge8Db+zaXw+cAmwDHgPOHvL4kqQhDBUCVXUf8PIB9R8Cxw+oF3DOMMeUJI2OTwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSw5YcAklWJfmvJHcl2Zrkr7r6hUkeTLKle53St835SbYluTvJiaP4ApKkpRtmeskngHdV1W3dZPO3JtnUrftwVX2wv3GSo4DTgaOBFwJfSnJkVT05RB8kSUNY8plAVe2oqtu65R8DdwEr5tnkVODqqnq8qr5Lb7L5Y5Z6fEnS8EZyTSDJauAVwNe70rlJbk+yIclBXW0F8EDfZtPMERpJ1iWZSjI1MzMzii5KkgYYOgSSPA+4FnhnVf0IuBR4MbAW2AFcPNt0wOY1aJ9Vtb6qJqtqcmJiYtguSpLmMFQIJHk2vQD4VFV9FqCqdlbVk1X1FPAJnh7ymQZW9W2+Etg+zPElScMZ5u6gAJcBd1XVh/rqh/U1ewNwZ7e8ETg9yQFJjgDWADcv9fiSpOENc3fQa4A3A3ck2dLV3gOckWQtvaGe+4G3AVTV1iTXAN+id2fROd4ZJEnjteQQqKqvMnic//p5trkIuGipx5QkjZZPDEtSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGrbsIZDkpCR3J9mW5LzlPr4k6WnLGgJJ9gM+CpwMHEVvKsqjlrMPkqSnLfeZwDHAtqq6r6p+BlwNnLrMfZAkdYaZaH4pVgAP9H2eBl69a6Mk64B13cefJLl7GfrWgoOBH4y7EwvJP4y7BxqTX4r/n7x30NTqzzi/vdiGyx0Cg/71ardC1Xpg/d7vTluSTFXV5Lj7IQ3i/8/xWO7hoGlgVd/nlcD2Ze6DJKmz3CFwC7AmyRFJngOcDmxc5j5IkjrLOhxUVU8kORe4AdgP2FBVW5ezD41ziE3PZP7/HINU7TYkL0lqhE8MS1LDDAFJapghIEkNW+7nBLSMkvwuvSeyV9B7HmM7sLGq7hprxyQ9Y3gmsI9K8m56f5YjwM30bs8NcJV/uE/SLO8O2kcl+Q5wdFX9fJf6c4CtVbVmPD2T5pfk7Kr6l3H3oxWeCey7ngJeOKB+WLdOeqZ677g70BKvCey73gncmOQenv6jfYcDvwOcO7ZeSUCS2+daBRy6nH1pncNB+7Akz6L357tX0PvhmgZuqaonx9oxNS/JTuBE4JFdVwH/U1WDzmK1F3gmsA+rqqeAzePuhzTA54HnVdWWXVck+fLyd6ddnglIUsO8MCxJDTMEJKlhhoA0hCSfTHLUuPshLZXXBKQFJAm9nxWfr9A+xzMBaYAkq5PcleRjwG3AZUmmkmxN8t6+dl9OMtkt/yTJRUm+mWRzEu931zOeISDN7SXAlVX1CuBd3SToLwP+IMnLBrR/LrC5ql4O3AT85fJ1VVoaQ0Ca2/eqavY5izcluQ34BnA0MOg6wM/o3f8OcCuweq/3UBqSD4tJc/tfgCRHAH8D/H5VPZLkcuBXBrT/eT19ke1J/PnSLwHPBKSFHUgvEB7txvlPHnN/pJHxNxVpAVX1zSTfALYC9wH/PeYuSSPjLaKS1DCHgySpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJatj/AXAaxJymUkCWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb9dd68a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print (example_df)\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print (grouped_data.groups)\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print (grouped_data.groups)\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print (grouped_data.sum())\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print (grouped_data.sum()['value'])\n",
    "    \n",
    "    print ('\\n') # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print (grouped_data['value'].sum())\n",
    "    \n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "#print(list(subway_df))\n",
    "temp_data = subway_df.groupby('rain').mean()['ENTRIESn_hourly']\n",
    "print(temp_data)\n",
    "#%pylab inline\n",
    "import seaborn as sns\n",
    "temp_data.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Calculating Hourly Entries and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1       NaN     NaN\n",
      "2      23.0     8.0\n",
      "3      14.0     8.0\n",
      "4      18.0    18.0\n",
      "5      29.0   205.0\n",
      "6      71.0    54.0\n",
      "7     132.0   593.0\n",
      "8     170.0    44.0\n"
     ]
    }
   ],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if False:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print (grouped_data['value'].apply(standardize))\n",
    "    \n",
    "# Find second largest value in each group\n",
    "if False:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print (grouped_data['value'].apply(second_largest))\n",
    "\n",
    "# --- Quiz ---\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "def shift_values(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "    \n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
    "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
    "    you copy it here and rename it, you can use it and the `.apply()`\n",
    "    function to help solve this problem.\n",
    "    '''\n",
    "    return entries_and_exits.groupby('UNIT')['ENTRIESn','EXITSn'].apply(shift_values)\n",
    "print(get_hourly_entries_and_exits(ridership_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Combining Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude  fog  \\\n",
      "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564    0   \n",
      "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564    0   \n",
      "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564    0   \n",
      "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564    0   \n",
      "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564    0   \n",
      "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135    0   \n",
      "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135    0   \n",
      "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135    0   \n",
      "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135    0   \n",
      "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135    0   \n",
      "\n",
      "   pressurei  rain  tempi  wspdi  \n",
      "0      30.24     0   52.0    8.1  \n",
      "1      30.32     0   48.9    6.9  \n",
      "2      30.14     0   54.0    3.5  \n",
      "3      29.98     0   57.2   15.0  \n",
      "4      30.01     0   48.9   15.0  \n",
      "5      30.24     0   52.0    8.1  \n",
      "6      30.32     0   48.9    6.9  \n",
      "7      30.14     0   54.0    3.5  \n",
      "8      29.98     0   57.2   15.0  \n",
      "9      30.01     0   48.9   15.0  \n"
     ]
    }
   ],
   "source": [
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return subway_df.merge(weather_df, on = ['DATEn', 'hour', 'latitude', 'longitude'], how = 'inner')\n",
    "print(combine_dfs(subway_df, weather_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Plotting for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# groupby() without as_index\n",
    "if False:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print (first_even)\n",
    "    print (first_even['even']) # Causes an error. 'even' is no longer a column in the DataFrame\n",
    "    \n",
    "# groupby() with as_index=False\n",
    "if False:\n",
    "    first_even = example_df.groupby('even', as_index=False).first()\n",
    "    print (first_even)\n",
    "    print (first_even['even']) # Now 'even' is still a column in the DataFrame\n",
    "\n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
