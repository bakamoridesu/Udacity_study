{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch  1, Batch   1 - Loss: 61719.2969 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch   2 - Loss: 37346.3281 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   3 - Loss: 36445.2266 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch   4 - Loss: 33193.1992 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   5 - Loss: 28262.4766 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch   6 - Loss: 26862.3633 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch   7 - Loss: 23232.1250 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch   8 - Loss: 21102.5156 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch   9 - Loss: 21413.6133 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  10 - Loss: 16090.2676 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  11 - Loss: 19703.0996 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  12 - Loss: 20249.8672 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  13 - Loss: 15904.3096 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  14 - Loss: 16829.9102 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  15 - Loss: 13447.4160 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  16 - Loss: 16244.9697 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  17 - Loss: 17389.7227 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  18 - Loss: 15209.9570 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  19 - Loss: 15072.1055 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  20 - Loss: 12507.2266 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  21 - Loss: 11257.0508 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  22 - Loss: 10719.2461 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  23 - Loss: 13702.2305 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  24 - Loss: 14025.3555 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  25 - Loss: 11248.6289 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  26 - Loss: 16384.6172 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  27 - Loss: 12111.7529 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  28 - Loss: 11103.5293 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  29 - Loss: 11185.4688 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  30 - Loss: 10254.3438 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  31 - Loss:  9959.3027 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  32 - Loss: 13326.6504 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  33 - Loss:  8656.7637 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  34 - Loss:  9694.6152 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  35 - Loss: 10271.5293 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  36 - Loss: 11271.6045 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  37 - Loss:  8572.5166 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  38 - Loss: 10133.8887 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  39 - Loss:  7833.1885 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  40 - Loss:  8444.0078 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  41 - Loss: 10091.6924 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  42 - Loss:  7792.2510 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  43 - Loss:  8469.7939 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  44 - Loss:  5871.2256 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  45 - Loss:  7042.0977 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  46 - Loss:  8580.4824 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  47 - Loss:  7604.2393 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  48 - Loss:  6736.8535 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  49 - Loss:  6107.1162 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  50 - Loss:  6014.1265 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  51 - Loss:  7047.4404 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  52 - Loss:  7448.1494 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  53 - Loss:  6177.3794 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  54 - Loss:  7090.8027 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  55 - Loss:  6938.3540 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  56 - Loss:  5723.6357 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  57 - Loss:  8679.6592 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  58 - Loss:  5197.0156 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch  59 - Loss:  5905.8330 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  60 - Loss:  8371.8916 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch  61 - Loss:  6665.4146 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch  62 - Loss:  6091.3984 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch  63 - Loss:  6450.7007 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  64 - Loss:  6746.1406 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  65 - Loss:  6820.7041 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch  66 - Loss:  4926.3438 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch  67 - Loss:  6280.3281 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  68 - Loss:  6087.3413 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch  69 - Loss:  5088.3936 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch  70 - Loss:  5565.9219 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  71 - Loss:  5927.4795 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch  72 - Loss:  6487.1235 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch  73 - Loss:  3764.0630 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch  74 - Loss:  6396.4282 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  75 - Loss:  4812.1772 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch  76 - Loss:  6519.9702 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch  77 - Loss:  5831.3887 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  78 - Loss:  4380.1660 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch  79 - Loss:  7426.1250 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch  80 - Loss:  7523.7090 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch  81 - Loss:  7688.9624 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch  82 - Loss:  4817.1807 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch  83 - Loss:  4965.1006 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch  84 - Loss:  4419.9775 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch  85 - Loss:  4572.3721 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  86 - Loss:  4222.1323 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch  87 - Loss:  4624.0752 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch  88 - Loss:  4015.0122 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch  89 - Loss:  5844.1167 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch  90 - Loss:  4145.2168 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch  91 - Loss:  5400.4624 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch  92 - Loss:  6366.9395 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch  93 - Loss:  5908.9980 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch  94 - Loss:  5090.2446 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch  95 - Loss:  4518.2559 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch  96 - Loss:  4599.6992 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch  97 - Loss:  4071.7261 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch  98 - Loss:  5608.9375 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch  99 - Loss:  5887.3525 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 100 - Loss:  5148.5024 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 101 - Loss:  4473.3174 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 102 - Loss:  4853.7393 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 103 - Loss:  5484.6865 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 104 - Loss:  4438.4932 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 105 - Loss:  5232.6182 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 106 - Loss:  4847.7783 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 107 - Loss:  3980.9971 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 108 - Loss:  2943.7026 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 109 - Loss:  3717.5818 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 110 - Loss:  4367.4087 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 111 - Loss:  2809.3433 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 112 - Loss:  4782.0986 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 113 - Loss:  2942.2258 Validation Accuracy: 0.703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 114 - Loss:  4460.0889 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 115 - Loss:  4964.8936 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 116 - Loss:  3437.8921 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 117 - Loss:  3977.3843 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 118 - Loss:  3289.3125 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 119 - Loss:  3620.8267 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 120 - Loss:  3541.4031 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 121 - Loss:  3389.4619 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 122 - Loss:  3696.7703 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 123 - Loss:  4837.0562 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 124 - Loss:  2890.9434 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 125 - Loss:  2793.5596 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 126 - Loss:  3005.9832 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 127 - Loss:  3838.3047 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 128 - Loss:  2870.8096 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 129 - Loss:  4211.9023 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 130 - Loss:  3322.2070 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 131 - Loss:  3882.0540 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 132 - Loss:  3624.7126 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 133 - Loss:  3742.1047 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 134 - Loss:  2638.9436 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 135 - Loss:  3848.0701 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 136 - Loss:  2960.9692 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 137 - Loss:  2745.9924 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 138 - Loss:  4577.5625 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 139 - Loss:  2609.8525 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 140 - Loss:  3244.4678 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 141 - Loss:  5333.6699 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 142 - Loss:  3264.3450 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 143 - Loss:  2872.5723 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 144 - Loss:  3656.3625 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 145 - Loss:  4055.4814 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 146 - Loss:  2813.3911 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 147 - Loss:  3072.8550 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 148 - Loss:  3442.0891 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 149 - Loss:  2337.5583 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 150 - Loss:  3654.2241 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 151 - Loss:  4188.6436 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 152 - Loss:  4575.2285 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 153 - Loss:  3833.5698 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 154 - Loss:  3373.2964 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 155 - Loss:  3630.3977 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 156 - Loss:  3013.1023 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 157 - Loss:  3212.7598 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 158 - Loss:  3192.4927 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 159 - Loss:  4012.4167 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 160 - Loss:  3196.9158 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 161 - Loss:  3096.1172 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 162 - Loss:  2478.5696 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 163 - Loss:  3057.2869 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 164 - Loss:  3274.7705 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 165 - Loss:  3345.8367 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 166 - Loss:  4402.3662 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 167 - Loss:  2671.1055 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 168 - Loss:  2603.6685 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 169 - Loss:  3581.7925 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 170 - Loss:  3403.6992 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 171 - Loss:  3891.4590 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 172 - Loss:  3692.7817 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 173 - Loss:  2453.8433 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 174 - Loss:  2840.6497 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 175 - Loss:  2672.4536 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 176 - Loss:  3712.9253 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 177 - Loss:  3295.0955 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 178 - Loss:  1902.1298 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 179 - Loss:  3783.0168 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 180 - Loss:  2544.7651 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 181 - Loss:  3404.4080 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 182 - Loss:  3499.0254 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 183 - Loss:  3451.9290 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 184 - Loss:  2753.3071 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 185 - Loss:  3231.3669 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 186 - Loss:  3031.2363 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 187 - Loss:  3104.4004 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 188 - Loss:  2246.8325 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 189 - Loss:  4508.0527 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 190 - Loss:  2799.4414 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 191 - Loss:  3228.7861 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 192 - Loss:  3815.1060 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 193 - Loss:  1948.9778 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 194 - Loss:  2970.0610 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 195 - Loss:  2681.0413 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 196 - Loss:  2065.9133 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 197 - Loss:  2234.3938 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 198 - Loss:  2296.7227 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 199 - Loss:  3501.4292 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 200 - Loss:  2869.6802 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 201 - Loss:  2620.6821 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 202 - Loss:  2559.5137 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 203 - Loss:  2840.4600 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 204 - Loss:  2140.8875 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 205 - Loss:  2043.6238 Validation Accuracy: 0.761719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e50f41ab6268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
